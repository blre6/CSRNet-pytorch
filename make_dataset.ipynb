{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import scipy.io as io\n",
    "import PIL.Image as Image\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.ndimage import gaussian_filter \n",
    "import scipy.spatial\n",
    "import json\n",
    "from matplotlib import cm as CM\n",
    "from image import *\n",
    "from model import CSRNet\n",
    "import torch\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this is borrowed from https://github.com/davideverona/deep-crowd-counting_crowdnet\n",
    "def gaussian_filter_density(gt):\n",
    "    print (gt.shape)\n",
    "    density = np.zeros(gt.shape, dtype=np.float32)\n",
    "    gt_count = np.count_nonzero(gt)\n",
    "    if gt_count == 0:\n",
    "        return density\n",
    "\n",
    "    pts = np.array(list(zip(np.nonzero(gt)[1], np.nonzero(gt)[0])))\n",
    "    leafsize = 2048\n",
    "    # build kdtree\n",
    "    tree = scipy.spatial.KDTree(pts.copy(), leafsize=leafsize)\n",
    "    # query kdtree\n",
    "    distances, locations = tree.query(pts, k=4)\n",
    "\n",
    "    print('generate density...')\n",
    "    for i, pt in enumerate(pts):\n",
    "        pt2d = np.zeros(gt.shape, dtype=np.float32)\n",
    "        pt2d[pt[1],pt[0]] = 1.\n",
    "        if gt_count > 1:\n",
    "            sigma = (distances[i][1]+distances[i][2]+distances[i][3])*0.1\n",
    "        else:\n",
    "            sigma = np.average(np.array(gt.shape))/2./2. #case: 1 point\n",
    "        density += scipy.ndimage.gaussian_filter(pt2d, sigma, mode='constant')\n",
    "    print('done.')\n",
    "    return density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#set the root to the Shanghai dataset you download\n",
    "root = r'datesets/ShanghaiTech'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now generate the ShanghaiA's ground truth\n",
    "part_A_train = os.path.join(root,'part_A_final/train_data','images')\n",
    "part_A_test = os.path.join(root,'part_A_final/test_data','images')\n",
    "part_B_train = os.path.join(root,'part_B_final/train_data','images')\n",
    "part_B_test = os.path.join(root,'part_B_final/test_data','images')\n",
    "path_sets = [part_B_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_paths = []\n",
    "for path in path_sets:\n",
    "    for img_path in glob.glob(os.path.join(path, '*.jpg')):\n",
    "        img_paths.append(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image  \n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from io import BytesIO\n",
    "\n",
    "# from torchvision import datasets, transforms\n",
    "# transform=transforms.Compose([\n",
    "#                        transforms.ToTensor(),transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "#                                      std=[0.229, 0.224, 0.225]),\n",
    "#                    ])\n",
    "# model = CSRNet()\n",
    "# model.eval()\n",
    "# model = model.to(\"cpu\")\n",
    "# checkpoint = torch.load('partBmodel_best.pth.tar', map_location='cpu')\n",
    "# model.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "# videoname = 'test.avi'\n",
    "# capture = cv2.VideoCapture(0)\n",
    "# writer=cv2.VideoWriter(\"hah.avi\",cv2.VideoWriter_fourcc(*'MJPG'),20.0,(128,96), True)\n",
    "# if capture.isOpened():\n",
    "#     while True:\n",
    "#         ret,img=capture.read() # img 就是一帧图片           \n",
    "#         # 可以用 cv2.imshow() 查看这一帧，也可以逐帧保存\n",
    "#         if not ret:break # 当获取完最后一帧就结束\n",
    "#         img = img[:, :, ::-1]\n",
    "#         img_pil = Image.fromarray(img)\n",
    "#         img = transform(img_pil.convert('RGB')).to(\"cpu\")\n",
    "#         output = model(img.unsqueeze(0))\n",
    "#         outputssss = np.squeeze(output.detach().cpu().numpy())\n",
    "#         plt.imshow(outputssss,cmap=CM.jet)\n",
    "#         tmpfile = BytesIO()\n",
    "#         plt.savefig(tmpfile)\n",
    "#         img_pil_density = Image.open(tmpfile)\n",
    "#         img_np_density = np.array(Image.open(tmpfile))\n",
    "#         # outputssss = cv2.resize(img_pil,(128,96))\n",
    "#         # print(type(outputssss))\n",
    "#         print(np.around(output.detach().cpu().sum().numpy()))\n",
    "#         writer.write(img_np_density)\n",
    "#         # img_pil_density.show()\n",
    "#         # img_pil.show()\n",
    "#         display(img_pil)\n",
    "#         display(img_pil_density)\n",
    "#         plt.clf()\n",
    "\n",
    "# else:\n",
    "#     print('视频打开失败！')\n",
    "# writer.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mat = io.loadmat(r'ShanghaiTech\\ShanghaiTech\\part_A_final/train_data\\ground_truth\\GT_IMG_1.mat')\n",
    "# img_path = r'ShanghaiTech\\ShanghaiTech\\part_A_final/train_data\\images\\IMG_1.jpg'\n",
    "# gt = mat[\"image_info\"][0,0][0,0][0]\n",
    "# img= plt.imread(img_path)\n",
    "# k = np.zeros((img.shape[0],img.shape[1]))\n",
    "# for i in range(0,len(gt)):\n",
    "#     if int(gt[i][1])<img.shape[0] and int(gt[i][0])<img.shape[1]:\n",
    "#         k[int(gt[i][1]),int(gt[i][0])]=1\n",
    "\n",
    "# density = np.zeros(gt.shape, dtype=np.float32)\n",
    "# gt_count = np.count_nonzero(gt)\n",
    "\n",
    "# pts = np.array(list(zip(np.nonzero(gt)[1], np.nonzero(gt)[0])))\n",
    "# leafsize = 2048\n",
    "# # build kdtree\n",
    "\n",
    "# tree = scipy.spatial.KDTree(pts, leafsize=leafsize)\n",
    "# # query kdtree\n",
    "# distances, locations = tree.query(pts, k=4)\n",
    "\n",
    "# print('generate density...')\n",
    "# for i, pt in enumerate(pts):\n",
    "#     pt2d = np.zeros(gt.shape, dtype=np.float32)\n",
    "#     pt2d[pt[1],pt[0]] = 1.\n",
    "#     if gt_count > 1:\n",
    "#         sigma = (distances[i][1]+distances[i][2]+distances[i][3])*0.1\n",
    "#     else:\n",
    "#         sigma = np.average(np.array(gt.shape))/2./2. #case: 1 point\n",
    "#     density += scipy.ndimage.filters.gaussian_filter(pt2d, sigma, mode='constant')\n",
    "# print('done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for img_path in img_paths[0:10]:\n",
    "    print(img_path)\n",
    "    mat = io.loadmat(img_path.replace('.jpg','.mat').replace('images','ground_truth').replace('IMG_','GT_IMG_'))\n",
    "    img= plt.imread(img_path)\n",
    "    k = np.zeros((img.shape[0],img.shape[1]))\n",
    "    gt = mat[\"image_info\"][0,0][0,0][0]\n",
    "    for i in range(0,len(gt)):\n",
    "        if int(gt[i][1])<img.shape[0] and int(gt[i][0])<img.shape[1]:\n",
    "            k[int(gt[i][1]),int(gt[i][0])]=1\n",
    "    print(type(k))\n",
    "    k = gaussian_filter_density(k)\n",
    "    with h5py.File(img_path.replace('.jpg','.h5').replace('images','ground_truth'), 'w') as hf:\n",
    "            hf['density'] = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now see a sample from ShanghaiA\n",
    "plt.imshow(Image.open(img_paths[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gt_file = h5py.File(img_paths[0].replace('.jpg','.h5').replace('images','ground_truth'),'r')\n",
    "groundtruth = np.asarray(gt_file['density'])\n",
    "plt.imshow(groundtruth,cmap=CM.jet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.sum(groundtruth)# don't mind this slight variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now generate the ShanghaiB's ground truth\n",
    "path_sets = [part_B_train,part_B_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_paths = []\n",
    "for path in path_sets:\n",
    "    for img_path in glob.glob(os.path.join(path, '*.jpg')):\n",
    "        img_paths.append(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for img_path in img_paths:\n",
    "    print (img_path)\n",
    "    mat = io.loadmat(img_path.replace('.jpg','.mat').replace('images','ground_truth').replace('IMG_','GT_IMG_'))\n",
    "    img= plt.imread(img_path)\n",
    "    k = np.zeros((img.shape[0],img.shape[1]))\n",
    "    gt = mat[\"image_info\"][0,0][0,0][0]\n",
    "    for i in range(0,len(gt)):\n",
    "        if int(gt[i][1])<img.shape[0] and int(gt[i][0])<img.shape[1]:\n",
    "            k[int(gt[i][1]),int(gt[i][0])]=1\n",
    "    k = gaussian_filter(k,15)\n",
    "    with h5py.File(img_path.replace('.jpg','.h5').replace('images','ground_truth'), 'w') as hf:\n",
    "            hf['density'] = k"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
